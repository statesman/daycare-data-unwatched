{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk import bigrams, ngrams, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_narratives = pd.read_csv('../export/injury-narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_narratives = dat_narratives.NARRATIVE.fillna(\n",
    "    ''\n",
    ").str.lower().str.strip().apply(\n",
    "    word_tokenize\n",
    ").apply(\n",
    "    lambda x: list(filter(\n",
    "        lambda y: y not in set(stopwords.words('english')) and y.isalpha(), x\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = tokenized_narratives.apply(\n",
    "    lambda x: pd.Series(x).unique()\n",
    ").apply(pd.Series).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fail\n",
    "# evidence\n",
    "# reported\n",
    "# arm\n",
    "# supervise\n",
    "# unsupervised\n",
    "# play\n",
    "# critical\n",
    "# toy\n",
    "# 48 hours\n",
    "\n",
    "# [a for a in \n",
    "word_counts = all_words.value_counts().apply(pd.Series).rename(\n",
    "    columns = {0: 'word count'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.head(20)\n",
    "\n",
    "word_counts.to_csv(\n",
    "    '../csv/narrative-word-counts.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_counts = all_words.apply(stemmer.stem).value_counts().apply(pd.Series).rename(\n",
    "    columns = {0: 'word count'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_narratives.apply(\n",
    "    bigrams\n",
    ").apply(list).apply(\n",
    "    pd.Series\n",
    ").stack().apply(\n",
    "    lambda x: ' '.join(x)\n",
    ").value_counts().loc[\n",
    "    lambda x: x >= 2\n",
    "].append(\n",
    "    # 6-grams\n",
    "    tokenized_narratives.apply(\n",
    "        lambda x: ngrams(x, 6)\n",
    "    ).apply(list).apply(\n",
    "        pd.Series\n",
    "    ).stack().apply(\n",
    "        lambda x: ' '.join(x)\n",
    "    ).value_counts().loc[lambda x: x >= 3]\n",
    ").append(\n",
    "    # 4-grams\n",
    "    tokenized_narratives.apply(\n",
    "        lambda x: ngrams(x, 4)\n",
    "    ).apply(list).apply(\n",
    "        pd.Series\n",
    "    ).stack().apply(\n",
    "        lambda x: ' '.join(x)\n",
    "    ).value_counts().loc[lambda x: x >= 3]\n",
    ").sort_values(ascending=False).apply(\n",
    "    pd.Series\n",
    ").rename(\n",
    "    columns = {0: 'count'}\n",
    ").assign(\n",
    "    is_jargon_phrase = lambda x: [\n",
    "        any(\n",
    "            jargon in index_phrase for jargon in ['based', 'obtained', 'standard', 'investigation found']\n",
    "        ) for index_phrase in x.index\n",
    "    ],\n",
    "    phrase_length = lambda x: [len(a.split(' ')) for a in x.index]\n",
    ").query('is_jargon_phrase == False').drop(\n",
    "    'is_jargon_phrase', axis=1\n",
    ").to_csv('../csv/narrative-phrase-counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
